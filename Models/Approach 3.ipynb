{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81pmKGUJhw3O",
        "outputId": "ad183b15-efad-43cc-f156-af220637b22d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eRxoQGQfgIKn",
        "outputId": "398b6a31-ee16-496f-9084-3de2a3e4ec14"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "import nltk\n",
        "nltk.download('wordnet')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4JB49mXcgeck",
        "outputId": "1fd4b8d8-8eaf-43b5-e883-e5a37579bda2"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OPXJ2xsig21y",
        "outputId": "acfeb6fa-862a-49c3-fdf9-317b4836d45b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk import pos_tag\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "# Load the Dataset file\n",
        "df = pd.read_csv('/content/drive/MyDrive/IMDB/train.csv')\n",
        "\n",
        "# Preprocessing text data\n",
        "def preprocess_text(text):\n",
        "    # Tokenization\n",
        "    tokens = word_tokenize(text)\n",
        "\n",
        "    # Remove stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [word for word in tokens if word.lower() not in stop_words]\n",
        "\n",
        "    # Lemmatization\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
        "\n",
        "    # POS Tagging\n",
        "    pos_tags = pos_tag(tokens)\n",
        "\n",
        "    return pos_tags\n",
        "\n",
        "# Apply preprocessing to each row in the dataframe\n",
        "df['review'] = df['review'].apply(preprocess_text)\n",
        "\n",
        "# Customized word embeddings\n",
        "sentences = df['review'].tolist()\n",
        "word2vec_model = Word2Vec(sentences, vector_size=100, window=5, min_count=1, workers=4)\n",
        "\n",
        "# Train-test split\n",
        "X = df['review']\n",
        "y = df['sentiment']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert text data to vectors using Bag-of-Words\n",
        "vectorizer = CountVectorizer(analyzer=lambda x: x)\n",
        "X_train_bow = vectorizer.fit_transform(X_train)\n",
        "X_test_bow = vectorizer.transform(X_test)\n",
        "\n",
        "# Train models\n",
        "models = {\n",
        "    \"Naive Bayes\": MultinomialNB(),\n",
        "    \"Random Forest\": RandomForestClassifier(),\n",
        "    \"k-NN\": KNeighborsClassifier()\n",
        "}\n",
        "\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train_bow, y_train)\n",
        "    y_pred = model.predict(X_test_bow)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(f\"{name} Accuracy: {accuracy}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZnJxjfB0ZCu",
        "outputId": "d823d1a1-8239-40ab-a671-ea2bda9762a8"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bayes Accuracy: 0.8541666666666666\n",
            "Random Forest Accuracy: 0.8405\n",
            "k-NN Accuracy: 0.5856666666666667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate on testing file\n",
        "test_data = pd.read_csv(\"/content/drive/MyDrive/IMDB/test.csv\")  # Load your testing data\n",
        "test_data['review'] = test_data['review'].apply(preprocess_text)\n",
        "X_test_final = vectorizer.transform(test_data['review'])\n",
        "y_test_final = test_data['sentiment']\n",
        "\n",
        "for name, model in models.items():\n",
        "    y_pred_test = model.predict(X_test_final)\n",
        "    acc_test = accuracy_score(y_test_final, y_pred_test)\n",
        "    print(f'{name} Test Accuracy: {acc_test}')"
      ],
      "metadata": {
        "id": "BdFuokRuagqr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5cb3dc2a-c5f0-4119-b3db-23a357b470d0"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bayes Test Accuracy: 0.85485\n",
            "Random Forest Test Accuracy: 0.8434\n",
            "k-NN Test Accuracy: 0.59035\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "J7zkjyyVkGKc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}